name: CI Workflow

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      repository-projects: write
      id-token: write

    steps:
      # Checkout the repository code
      - name: Checkout repository
        uses: actions/checkout@v2

      # Install uv (Universal Viewer) CLI, similar to conda
      - name: Install uv
        uses: astral-sh/setup-uv@v2

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # DVC: Create credentials.json
      - name: Create credentials.json
        env:
          GDRIVE_CREDENTIALS_DATA: ${{ secrets.GDRIVE_CREDENTIALS_DATA }}  # Fix typo in secret name
        run: echo "$GDRIVE_CREDENTIALS_DATA" > credentials.json

      # Modify DVC Remote
      - name: Modify DVC Remote
        run: |
          uv run dvc remote modify --local gdrive-remote gdrive_service_account_json_file_path credentials.json

      # DVC Pull Data
      - name: DVC Pull Data
        run: |
          uv run dvc pull -v

      # Verify that the test data exists
      - name: Verify test data directory
        run: |
          if [ ! -d "./data/test/sea" ]; then
            echo "Directory ./data/test/sea does not exist!"
            exit 1
          fi

      # Run CNN Ship Filter Inference
      - name: Run tests
        run: |
          mkdir -p /home/runner/work/classification-pytorch/classification-pytorch/plots
          python3 main.py --mode test --data_path ./data/test/ --model_path ./models/cnn_resnet18_freeze_backbone_False.pth
